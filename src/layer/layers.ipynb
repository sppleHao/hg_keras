{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam , RMSprop\n",
    "from keras.losses import mean_squared_error\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convBlock(inputs,num_out_channels,name):\n",
    "    x = Conv2D(num_out_channels // 2,kernel_size=(1,1),activation='relu',padding='same',name=name+'_conv_1x1_x1')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(num_out_channels // 2,kernel_size=(3,3),activation='relu',padding='same',name=name+'_conv_3x3_x2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(num_out_channels , kernel_size=(1,1),activation='relu',padding='same',name=name+'_conv_1x1_x3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipLayer(inputs,num_out_channels,name):\n",
    "    if K.int_shape(inputs)[-1]==num_out_channels:\n",
    "        skip=inputs\n",
    "    else:\n",
    "        skip=Conv2D(num_out_channels,kernel_size=(1,1),activation='relu',padding='same',name=name+'_skip_conv')(inputs)\n",
    "    return skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(inputs, num_out_channels, name):\n",
    "    \"\"\"\n",
    "    Create a Convolutional Layer + Batch Normalization + ReLU Activation \n",
    "    args :\n",
    "    inputs : (tf.Tensor)\n",
    "    numOut : (int)\n",
    "    return :\n",
    "    tf.Tensor\n",
    "    \"\"\"\n",
    "    convb = convBlock(inputs,num_out_channels,name+'convBlock')\n",
    "    skip = skipLayer(inputs,num_out_channels,name+'skipLayer')\n",
    "    add = Add()([convb,skip])  \n",
    "    return add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hourglass_network(num_classes, num_stacks, num_channels, inres, outres, residual_type):\n",
    "    inputs = Input(shape=(inres[0],inres[1],3))\n",
    "    \n",
    "    front_features = create_front_module(inputs,num_channels,residual_type)\n",
    "    \n",
    "    head_next_stage = front_features\n",
    "    \n",
    "    outputs = []\n",
    "    for i in range(num_stacks):\n",
    "        head_next_stage,head_to_loss = hourglass_module(head_next_stage,num_classes,num_channels,residual_type,i)\n",
    "        outputs.append(head_to_loss)\n",
    "        \n",
    "    model = Model(inputs=inputs,outputs=outputs)\n",
    "    rms =RMSprop(lr=5e-4)\n",
    "    model.compile(optimizer=rms,loss=mean_squared_error,metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_front_module(inputs,num_channels,residual_type):\n",
    "    x = Conv2D(64,kernel_size=(7,7),strides=(2,2),activation='relu',padding='same',name='front_conv_7x7_x1')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = residual_type(x,num_channels//2,'front_residual_x1')\n",
    "    x = MaxPool2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "    \n",
    "    x = residual_type(x,num_channels//2,'front_residual_x2')\n",
    "    x = residual_type(x,num_channels,'front_residual_x3')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourglass_module(inputs, num_classes, num_channels, residual_type, hg_id):\n",
    "    # create left features , f1, f2, f4, and f8\n",
    "    left_features = create_left_half_blocks(inputs,residual_type,num_channels,hg_id)\n",
    "    \n",
    "    # create right features, connect with left features\n",
    "    rf1 =create_right_half_blocks(left_features,residual_type,num_channels,hg_id)\n",
    "    \n",
    "    # add 1x1 conv with two heads, head_next_stage is sent to next stage\n",
    "    # head_parts is used for intermediate supervision\n",
    "    head_next_stage,head_parts = create_heads(inputs,rf1,num_classes,num_channels,hg_id)\n",
    "    \n",
    "    return head_next_stage,head_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_left_half_blocks(inputs, residual_type, num_channels,hg_id):\n",
    "    # create left half blocks for hourglass module\n",
    "    # f1, f2, f4 , f8 : 1, 1/2, 1/4 1/8 resolution\n",
    "    hg_name = 'hg_'+str(hg_id)\n",
    "    \n",
    "    f1 = residual_type(inputs,num_channels,hg_name+'_l1')\n",
    "    x = MaxPool2D(pool_size=(2,2),strides=(2,2))(f1)\n",
    "    \n",
    "    f2 = residual_type(x,num_channels,hg_name+'_l2')\n",
    "    x = MaxPool2D(pool_size=(2,2),strides=(2,2))(f2)\n",
    "    \n",
    "    f4 = residual_type(x,num_channels,hg_name+'_l4')\n",
    "    x = MaxPool2D(pool_size=(2,2),strides=(2,2))(f4)\n",
    "    \n",
    "    f8 = residual_type(x,num_channels,hg_name+'_l8')\n",
    "    \n",
    "    return (f1,f2,f4,f8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_right_half_blocks(left_features,residual_type,num_channels,hg_id):\n",
    "    lf1 ,lf2 ,lf4 ,lf8 = left_features\n",
    "    \n",
    "    rf8 = bottom_layer(lf8, residual_type, num_channels,hg_id)\n",
    "    \n",
    "    rf4 = connect_left_to_right(lf4,rf8,residual_type,num_channels,str(hg_id)+'_rf4')\n",
    "    \n",
    "    rf2 = connect_left_to_right(lf2,rf4,residual_type,num_channels,str(hg_id)+'_rf2')\n",
    "    \n",
    "    rf1 = connect_left_to_right(lf1,rf2,residual_type,num_channels,str(hg_id)+'_rf1')\n",
    "\n",
    "    return rf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottom_layer(lf8, residual_type, num_channels,hg_id):\n",
    "    # blocks in lowest resolution\n",
    "    # 3 residual blocks + Add\n",
    "    lf8_connect = residual_type(lf8,num_channels,str(hg_id)+'_lf8')\n",
    "    \n",
    "    x = residual_type(lf8,num_channels,str(hg_id)+'_lf8_resi_x1')\n",
    "    x = residual_type(x,num_channels,str(hg_id)+'_lf8_resi_x2')\n",
    "    x = residual_type(x,num_channels,str(hg_id)+'_lf8_resi_x3')\n",
    "    \n",
    "    add = Add()([x,lf8_connect])\n",
    "    \n",
    "    return add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_left_to_right(lf,rf,residual_type,num_channels,name):\n",
    "    \n",
    "    # left with 1 residual\n",
    "    # right upsampling\n",
    "    # connect layers and with 1 residual \n",
    "    \n",
    "    xleft = residual_type(lf,num_channels,name+'_connect_left_resi')\n",
    "    xright = UpSampling2D()(rf)\n",
    "    add = Add()([xleft,xright])\n",
    "    out = residual_type(add,num_channels,name+'_connect')\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heads(pre_layer_features, rf1, num_classes, num_channels, hg_id):\n",
    "    # two head, one head to next stage, one head to intermediate features\n",
    "    \n",
    "    name = '_head'\n",
    "    \n",
    "    head = Conv2D(num_channels,kernel_size=(1,1),activation='relu',padding='same',name=str(hg_id)+name+'_conv_1x1_x1')(rf1)\n",
    "    head = BatchNormalization()(head)\n",
    "    \n",
    "    # for head as intermediate supervision, use 'linear' as activation.\n",
    "    head_parts = Conv2D(num_classes,kernel_size=(1,1),activation='linear',padding='same',name=str(hg_id)+name + '_conv_1x1_parts')(head)\n",
    "    \n",
    "    # use linear activations\n",
    "    head_connect = Conv2D(num_channels,kernel_size=(1,1),activation='linear',padding='same',name=str(hg_id)+ name +'_conv_1x1_x2')(head)\n",
    "    head_parts_connect = Conv2D(num_channels,kernel_size=(1,1),activation='linear',padding='same',name=str(hg_id)+ name+'_conv_1x1_x3')(head_parts)\n",
    "    \n",
    "    # connect \n",
    "    head_next_stage = Add()([head_connect,head_parts_connect,pre_layer_features])\n",
    "    \n",
    "    return head_next_stage,head_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_loss(x, y):\n",
    "    return K.sqrt(K.sum(K.square(x - y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
